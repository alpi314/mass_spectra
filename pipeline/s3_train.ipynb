{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Step 3 in the Pipeline - Training ML Prediction Model\n",
    "With this notebook we can train various ML classifiers to tackle multi-lable prediction problem. We are predicting Spec2Vec embeddings from molecular fingerprints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score, jaccard_score, roc_auc_score, hamming_loss, label_ranking_loss, coverage_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import  ClassifierChain\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mass_spectra.similarity_voting import SimilarityVoting\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import shuffle, seed\n",
    "from math import ceil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 27082023\n",
    "seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# path to merged fingerprint and embedding data (fingerprint columns should be prefixed with 'fingerprint_' and embedding columns should be prefixed with 'embedding_').\n",
    "MERGED_PATH = './source/embedding/all_positive_tms_maccs/merged.csv'\n",
    "MODEL_OUTPUT_FOLDER = \"./source/model/all_positive_tms_maccs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(MERGED_PATH)\n",
    "assert os.path.isdir(MODEL_OUTPUT_FOLDER)\n",
    "assert MERGED_PATH.endswith('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATOR = RandomForestClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = OneVsRestClassifier(ESTIMATOR, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT_FOLDER = f'{MODEL_OUTPUT_FOLDER}{MODEL.__class__.__name__}_{ESTIMATOR.__class__.__name__}'\n",
    "os.makedirs(f'{MODEL_OUTPUT_FOLDER}/models', exist_ok=False)\n",
    "os.makedirs(f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_models', exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Definition\n",
    "Creates metrics which can be called with (y_true, y_prob, y_pred) for easier use. It also creates multiple combinations of metrics for different averaging methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PRED_SCORES = [accuracy_score, log_loss, hamming_loss] # input y predictions and y true\n",
    "Y_PRED_SCORES_WITH_AVERAGING = [f1_score, precision_score, recall_score, jaccard_score] # input y predictions and y true and use one of the following: \"micro\", \"macro\", \"weighted\", \"samples\"\n",
    "Y_PROB_SCORES = [roc_auc_score, label_ranking_loss, coverage_error] # input y probabilities and y true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = []\n",
    "METRIC_NAMES = []\n",
    "for metric in Y_PRED_SCORES:\n",
    "    METRICS.append(lambda y_true, y_prob, y_pred, metric=metric: metric(y_true, y_pred))\n",
    "    METRIC_NAMES.append(metric.__name__)\n",
    "for metric in Y_PRED_SCORES_WITH_AVERAGING:\n",
    "    for average in [\"micro\", \"macro\", \"weighted\", \"samples\"]:\n",
    "        zero_division = 0 if metric.__name__ == \"jaccard_score\" else np.nan\n",
    "        METRICS.append(lambda y_true, y_prob, y_pred, metric=metric, average=average: metric(y_true, y_pred, average=average, zero_division=zero_division))\n",
    "        METRIC_NAMES.append(metric.__name__ + \"__\" + average)\n",
    "for metric in Y_PROB_SCORES:\n",
    "    METRICS.append(lambda y_true, y_prob, y_pred, metric=metric: metric(y_true, y_prob))\n",
    "    METRIC_NAMES.append(metric.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, metrics, metric_names, repeats=2, folds=5):\n",
    "        self.metrics = metrics\n",
    "        self.metric_names = metric_names\n",
    "        \n",
    "        self.repeats = repeats\n",
    "        self.folds = folds\n",
    "        self.i = 0\n",
    "\n",
    "        self.results = pd.DataFrame(columns=['repeat', 'fold', 'model_training_data_path'] + self.metric_names)\n",
    "    \n",
    "    def evaluate(self, y_true, y_prob, y_pred, model_training_data_path=None):\n",
    "        entry = {\n",
    "            'repeat': self.i // self.folds,\n",
    "            'fold': self.i % self.folds,\n",
    "            'model_training_data_path': model_training_data_path\n",
    "        }\n",
    "        for metric, metric_name in zip(self.metrics, self.metric_names):\n",
    "            try:\n",
    "                entry[metric_name] = metric(y_true, y_prob, y_pred)\n",
    "            except ValueError as e:\n",
    "                print(\"Warning: \", e)\n",
    "                entry[metric_name] = np.nan\n",
    "        \n",
    "        self.results = pd.concat([self.results, pd.DataFrame(entry, index=[0])], ignore_index=True)\n",
    "        self.i += 1\n",
    "    \n",
    "    def store(self, filename):\n",
    "        self.results.to_csv(filename, index=False)\n",
    "\n",
    "    def current(self, metric_name):\n",
    "        return self.results[metric_name].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3025 entries, 0 to 3024\n",
      "Columns: 467 entries, inchi_key to embedding_299\n",
      "dtypes: float64(466), object(1)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv(MERGED_PATH)\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of NaNs: 0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Number of NaNs: {merged_df.isna().sum().sum()}' # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3025, 300), (3025, 166))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = merged_df.filter(regex='^embedding_')\n",
    "y = merged_df.filter(regex='^fingerprint_')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train- K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6985a2ff0f74eceab9c75cd117acc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeats:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ddf77057074651b5b8b382f3412010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.011956754964315969\n",
      "F1 Weighted:  0.8230053582561405\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleks\\Projects\\IJS\\mass_spectra\\pipeline\\s3_train.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/IJS/mass_spectra/pipeline/s3_train.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X[train_index], X[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/IJS/mass_spectra/pipeline/s3_train.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/IJS/mass_spectra/pipeline/s3_train.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m MODEL\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/IJS/mass_spectra/pipeline/s3_train.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# predict\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/IJS/mass_spectra/pipeline/s3_train.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_pred \u001b[39m=\u001b[39m MODEL\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\multiclass.py:339\u001b[0m, in \u001b[0;36mOneVsRestClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    335\u001b[0m columns \u001b[39m=\u001b[39m (col\u001b[39m.\u001b[39mtoarray()\u001b[39m.\u001b[39mravel() \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m Y\u001b[39m.\u001b[39mT)\n\u001b[0;32m    336\u001b[0m \u001b[39m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)(\n\u001b[0;32m    340\u001b[0m     delayed(_fit_binary)(\n\u001b[0;32m    341\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator,\n\u001b[0;32m    342\u001b[0m         X,\n\u001b[0;32m    343\u001b[0m         column,\n\u001b[0;32m    344\u001b[0m         classes\u001b[39m=\u001b[39;49m[\n\u001b[0;32m    345\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mnot \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_binarizer_\u001b[39m.\u001b[39;49mclasses_[i],\n\u001b[0;32m    346\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_binarizer_\u001b[39m.\u001b[39;49mclasses_[i],\n\u001b[0;32m    347\u001b[0m         ],\n\u001b[0;32m    348\u001b[0m     )\n\u001b[0;32m    349\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, column \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(columns)\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    353\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "REPEATS = 2\n",
    "K = 5\n",
    "metrics = Metrics(METRICS, METRIC_NAMES, REPEATS, K)\n",
    "\n",
    "for i in tqdm(range(REPEATS), desc=\"Repeats\"):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE + i)\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X, y)), desc=\"Fold\", total=K):\n",
    "        # train\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MODEL.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = MODEL.predict(X_test)\n",
    "        y_prob = MODEL.predict_proba(X_test)\n",
    "\n",
    "        # store train data\n",
    "        model_training_data_path = f'{MODEL_OUTPUT_FOLDER}/models/{i}_{fold}.pkl'\n",
    "        with open(model_training_data_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"model\": MODEL,\n",
    "                \"X_train\": X_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_test\": y_test,\n",
    "            }, f)\n",
    "\n",
    "        # evaluate\n",
    "        metrics.evaluate(y_test, y_prob, y_pred, model_training_data_path=model_training_data_path)\n",
    "\n",
    "        # display current results\n",
    "        print('Label ranking loss: ', metrics.current('label_ranking_loss'))\n",
    "        print('F1 Weighted: ', metrics.current('f1_score__weighted'))\n",
    "        \n",
    "metrics.store(f'{MODEL_OUTPUT_FOLDER}/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>f1_score__micro</th>\n",
       "      <th>f1_score__macro</th>\n",
       "      <th>f1_score__weighted</th>\n",
       "      <th>f1_score__samples</th>\n",
       "      <th>precision_score__micro</th>\n",
       "      <th>precision_score__macro</th>\n",
       "      <th>precision_score__weighted</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_score__macro</th>\n",
       "      <th>recall_score__weighted</th>\n",
       "      <th>recall_score__samples</th>\n",
       "      <th>jaccard_score__micro</th>\n",
       "      <th>jaccard_score__macro</th>\n",
       "      <th>jaccard_score__weighted</th>\n",
       "      <th>jaccard_score__samples</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>label_ranking_loss</th>\n",
       "      <th>coverage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.060496</td>\n",
       "      <td>273.823179</td>\n",
       "      <td>0.047163</td>\n",
       "      <td>0.886091</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>0.887575</td>\n",
       "      <td>0.893221</td>\n",
       "      <td>0.581024</td>\n",
       "      <td>0.894957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566313</td>\n",
       "      <td>0.879092</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.795508</td>\n",
       "      <td>0.478783</td>\n",
       "      <td>0.820357</td>\n",
       "      <td>0.809726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>59.741983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008649</td>\n",
       "      <td>10.952253</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>1.614533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.044628</td>\n",
       "      <td>258.728597</td>\n",
       "      <td>0.043861</td>\n",
       "      <td>0.876722</td>\n",
       "      <td>0.557985</td>\n",
       "      <td>0.875114</td>\n",
       "      <td>0.880635</td>\n",
       "      <td>0.888146</td>\n",
       "      <td>0.560778</td>\n",
       "      <td>0.888120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538535</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.879676</td>\n",
       "      <td>0.780503</td>\n",
       "      <td>0.463335</td>\n",
       "      <td>0.807065</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>56.704132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.056612</td>\n",
       "      <td>266.456173</td>\n",
       "      <td>0.045835</td>\n",
       "      <td>0.883493</td>\n",
       "      <td>0.563243</td>\n",
       "      <td>0.882572</td>\n",
       "      <td>0.885157</td>\n",
       "      <td>0.891211</td>\n",
       "      <td>0.572672</td>\n",
       "      <td>0.893247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561979</td>\n",
       "      <td>0.875198</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.791301</td>\n",
       "      <td>0.472386</td>\n",
       "      <td>0.816186</td>\n",
       "      <td>0.806053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>59.198760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060331</td>\n",
       "      <td>274.842925</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>0.886685</td>\n",
       "      <td>0.573175</td>\n",
       "      <td>0.885612</td>\n",
       "      <td>0.887811</td>\n",
       "      <td>0.893128</td>\n",
       "      <td>0.583809</td>\n",
       "      <td>0.894849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566068</td>\n",
       "      <td>0.878853</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.482580</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>0.809918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>59.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.066942</td>\n",
       "      <td>282.187079</td>\n",
       "      <td>0.048755</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.574847</td>\n",
       "      <td>0.889640</td>\n",
       "      <td>0.889599</td>\n",
       "      <td>0.894935</td>\n",
       "      <td>0.587085</td>\n",
       "      <td>0.897842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571242</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>0.891925</td>\n",
       "      <td>0.800504</td>\n",
       "      <td>0.483973</td>\n",
       "      <td>0.825789</td>\n",
       "      <td>0.812804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>60.830579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.072727</td>\n",
       "      <td>291.408865</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.892106</td>\n",
       "      <td>0.580663</td>\n",
       "      <td>0.891919</td>\n",
       "      <td>0.893260</td>\n",
       "      <td>0.898244</td>\n",
       "      <td>0.599626</td>\n",
       "      <td>0.899495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584225</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.896502</td>\n",
       "      <td>0.805226</td>\n",
       "      <td>0.491301</td>\n",
       "      <td>0.829325</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>62.348760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score    log_loss  hamming_loss  f1_score__micro  \\\n",
       "count       10.000000   10.000000     10.000000        10.000000   \n",
       "mean         0.060496  273.823179      0.047163         0.886091   \n",
       "std          0.008649   10.952253      0.002151         0.004672   \n",
       "min          0.044628  258.728597      0.043861         0.876722   \n",
       "25%          0.056612  266.456173      0.045835         0.883493   \n",
       "50%          0.060331  274.842925      0.046754         0.886685   \n",
       "75%          0.066942  282.187079      0.048755         0.889200   \n",
       "max          0.072727  291.408865      0.050961         0.892106   \n",
       "\n",
       "       f1_score__macro  f1_score__weighted  f1_score__samples  \\\n",
       "count        10.000000           10.000000          10.000000   \n",
       "mean          0.569981            0.885600           0.887575   \n",
       "std           0.007729            0.005202           0.004048   \n",
       "min           0.557985            0.875114           0.880635   \n",
       "25%           0.563243            0.882572           0.885157   \n",
       "50%           0.573175            0.885612           0.887811   \n",
       "75%           0.574847            0.889640           0.889599   \n",
       "max           0.580663            0.891919           0.893260   \n",
       "\n",
       "       precision_score__micro  precision_score__macro  \\\n",
       "count               10.000000               10.000000   \n",
       "mean                 0.893221                0.581024   \n",
       "std                  0.003414                0.011741   \n",
       "min                  0.888146                0.560778   \n",
       "25%                  0.891211                0.572672   \n",
       "50%                  0.893128                0.583809   \n",
       "75%                  0.894935                0.587085   \n",
       "max                  0.898244                0.599626   \n",
       "\n",
       "       precision_score__weighted  ...  recall_score__macro  \\\n",
       "count                  10.000000  ...            10.000000   \n",
       "mean                    0.894957  ...             0.566313   \n",
       "std                     0.003476  ...             0.012845   \n",
       "min                     0.888120  ...             0.538535   \n",
       "25%                     0.893247  ...             0.561979   \n",
       "50%                     0.894849  ...             0.566068   \n",
       "75%                     0.897842  ...             0.571242   \n",
       "max                     0.899495  ...             0.584225   \n",
       "\n",
       "       recall_score__weighted  recall_score__samples  jaccard_score__micro  \\\n",
       "count               10.000000              10.000000             10.000000   \n",
       "mean                 0.879092               0.888414              0.795508   \n",
       "std                  0.006948               0.005103              0.007515   \n",
       "min                  0.865589               0.879676              0.780503   \n",
       "25%                  0.875198               0.885079              0.791301   \n",
       "50%                  0.878853               0.888429              0.796436   \n",
       "75%                  0.885018               0.891925              0.800504   \n",
       "max                  0.888018               0.896502              0.805226   \n",
       "\n",
       "       jaccard_score__macro  jaccard_score__weighted  jaccard_score__samples  \\\n",
       "count             10.000000                10.000000               10.000000   \n",
       "mean               0.478783                 0.820357                0.809726   \n",
       "std                0.008929                 0.006996                0.006062   \n",
       "min                0.463335                 0.807065                0.799600   \n",
       "25%                0.472386                 0.816186                0.806053   \n",
       "50%                0.482580                 0.820623                0.809918   \n",
       "75%                0.483973                 0.825789                0.812804   \n",
       "max                0.491301                 0.829325                0.818455   \n",
       "\n",
       "       roc_auc_score  label_ranking_loss  coverage_error  \n",
       "count            0.0           10.000000       10.000000  \n",
       "mean             NaN            0.020618       59.741983  \n",
       "std              NaN            0.001522        1.614533  \n",
       "min              NaN            0.018639       56.704132  \n",
       "25%              NaN            0.019547       59.198760  \n",
       "50%              NaN            0.020482       59.727273  \n",
       "75%              NaN            0.021571       60.830579  \n",
       "max              NaN            0.023544       62.348760  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With Unseen InChI Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, test_inchi_keys=[]):\n",
    "    # get index from merged_df\n",
    "    test_index = merged_df[merged_df['inchi_key'].isin(test_inchi_keys)].index\n",
    "    train_index = merged_df[~merged_df['inchi_key'].isin(test_inchi_keys)].index\n",
    "\n",
    "    # split X and y\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inchi_keys = list(merged_df['inchi_key'].unique())\n",
    "shuffle(all_inchi_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42c775486df4cd08c710f3f13938bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeats:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14450dee02a3464ab5fbe568efbdc43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hidden_inchi_keys = 10\n",
    "\n",
    "REPEATS = 1\n",
    "K = ceil(len(all_inchi_keys) / hidden_inchi_keys)\n",
    "metrics = Metrics(METRICS, METRIC_NAMES, REPEATS, K)\n",
    "\n",
    "for i in tqdm(range(REPEATS), desc=\"Repeats\"):\n",
    "    # Reshuffle\n",
    "    shuffle(all_inchi_keys)\n",
    "\n",
    "    for end_i in tqdm(range(hidden_inchi_keys, len(all_inchi_keys), hidden_inchi_keys), desc=\"Fold\", total=K):\n",
    "        start_i = end_i - hidden_inchi_keys\n",
    "        if end_i + hidden_inchi_keys > len(all_inchi_keys):\n",
    "            end_i = len(all_inchi_keys)\n",
    "\n",
    "        # train\n",
    "        test_inchi_keys = all_inchi_keys[start_i:end_i]\n",
    "        X_train, X_test, y_train, y_test = split_dataset(X, y, test_inchi_keys)\n",
    "\n",
    "        MODEL.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = MODEL.predict(X_test)\n",
    "        y_prob = MODEL.predict_proba(X_test)\n",
    "\n",
    "        # store train data\n",
    "        model_training_data_path = f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_models/{start_i}_{end_i}.pkl'\n",
    "        with open(model_training_data_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"model\": MODEL,\n",
    "                \"X_train\": X_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_test\": y_test,\n",
    "            }, f)\n",
    "\n",
    "        # evaluate\n",
    "        metrics.evaluate(y_test, y_prob, y_pred, model_training_data_path=model_training_data_path)\n",
    "\n",
    "        # display current results\n",
    "        print('Label ranking loss: ', metrics.current('label_ranking_loss'))\n",
    "        print('F1 Weighted: ', metrics.current('f1_score__weighted'))\n",
    "\n",
    "metrics.store(f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>f1_score__micro</th>\n",
       "      <th>f1_score__macro</th>\n",
       "      <th>f1_score__weighted</th>\n",
       "      <th>f1_score__samples</th>\n",
       "      <th>precision_score__micro</th>\n",
       "      <th>precision_score__macro</th>\n",
       "      <th>precision_score__weighted</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_score__macro</th>\n",
       "      <th>recall_score__weighted</th>\n",
       "      <th>recall_score__samples</th>\n",
       "      <th>jaccard_score__micro</th>\n",
       "      <th>jaccard_score__macro</th>\n",
       "      <th>jaccard_score__weighted</th>\n",
       "      <th>jaccard_score__samples</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>label_ranking_loss</th>\n",
       "      <th>coverage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011130</td>\n",
       "      <td>424.566557</td>\n",
       "      <td>0.092088</td>\n",
       "      <td>0.775859</td>\n",
       "      <td>0.258890</td>\n",
       "      <td>0.773875</td>\n",
       "      <td>0.782796</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.288535</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257364</td>\n",
       "      <td>0.761034</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.634953</td>\n",
       "      <td>0.215581</td>\n",
       "      <td>0.708030</td>\n",
       "      <td>0.661918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060978</td>\n",
       "      <td>86.985411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016413</td>\n",
       "      <td>98.875142</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>0.035569</td>\n",
       "      <td>0.042875</td>\n",
       "      <td>0.031595</td>\n",
       "      <td>0.042661</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.048066</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>0.026899</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.040484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>12.870083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.356940</td>\n",
       "      <td>0.069487</td>\n",
       "      <td>0.716793</td>\n",
       "      <td>0.192055</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.729632</td>\n",
       "      <td>0.713917</td>\n",
       "      <td>0.206776</td>\n",
       "      <td>0.737883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185742</td>\n",
       "      <td>0.695205</td>\n",
       "      <td>0.718066</td>\n",
       "      <td>0.558595</td>\n",
       "      <td>0.171804</td>\n",
       "      <td>0.629265</td>\n",
       "      <td>0.596405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037725</td>\n",
       "      <td>68.509554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>352.628408</td>\n",
       "      <td>0.082038</td>\n",
       "      <td>0.759725</td>\n",
       "      <td>0.240218</td>\n",
       "      <td>0.740072</td>\n",
       "      <td>0.765759</td>\n",
       "      <td>0.770019</td>\n",
       "      <td>0.251891</td>\n",
       "      <td>0.804088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244163</td>\n",
       "      <td>0.713567</td>\n",
       "      <td>0.744621</td>\n",
       "      <td>0.612625</td>\n",
       "      <td>0.199911</td>\n",
       "      <td>0.664556</td>\n",
       "      <td>0.637618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050587</td>\n",
       "      <td>76.458898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.006109</td>\n",
       "      <td>374.263650</td>\n",
       "      <td>0.087952</td>\n",
       "      <td>0.784315</td>\n",
       "      <td>0.261130</td>\n",
       "      <td>0.784945</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>0.796566</td>\n",
       "      <td>0.291311</td>\n",
       "      <td>0.813472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259274</td>\n",
       "      <td>0.775593</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>0.645179</td>\n",
       "      <td>0.213979</td>\n",
       "      <td>0.714587</td>\n",
       "      <td>0.670641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059758</td>\n",
       "      <td>86.720199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.012200</td>\n",
       "      <td>506.283899</td>\n",
       "      <td>0.102982</td>\n",
       "      <td>0.791712</td>\n",
       "      <td>0.272094</td>\n",
       "      <td>0.804507</td>\n",
       "      <td>0.793287</td>\n",
       "      <td>0.815267</td>\n",
       "      <td>0.307515</td>\n",
       "      <td>0.844446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265805</td>\n",
       "      <td>0.803753</td>\n",
       "      <td>0.818344</td>\n",
       "      <td>0.655235</td>\n",
       "      <td>0.222074</td>\n",
       "      <td>0.750225</td>\n",
       "      <td>0.672976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066355</td>\n",
       "      <td>96.865680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.054140</td>\n",
       "      <td>598.977735</td>\n",
       "      <td>0.118474</td>\n",
       "      <td>0.819505</td>\n",
       "      <td>0.318622</td>\n",
       "      <td>0.829669</td>\n",
       "      <td>0.826830</td>\n",
       "      <td>0.864236</td>\n",
       "      <td>0.379419</td>\n",
       "      <td>0.867883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312009</td>\n",
       "      <td>0.815877</td>\n",
       "      <td>0.839398</td>\n",
       "      <td>0.694205</td>\n",
       "      <td>0.267533</td>\n",
       "      <td>0.777955</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089780</td>\n",
       "      <td>108.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score    log_loss  hamming_loss  f1_score__micro  \\\n",
       "count       10.000000   10.000000     10.000000        10.000000   \n",
       "mean         0.011130  424.566557      0.092088         0.775859   \n",
       "std          0.016413   98.875142      0.017652         0.034530   \n",
       "min          0.000000  319.356940      0.069487         0.716793   \n",
       "25%          0.000814  352.628408      0.082038         0.759725   \n",
       "50%          0.006109  374.263650      0.087952         0.784315   \n",
       "75%          0.012200  506.283899      0.102982         0.791712   \n",
       "max          0.054140  598.977735      0.118474         0.819505   \n",
       "\n",
       "       f1_score__macro  f1_score__weighted  f1_score__samples  \\\n",
       "count        10.000000           10.000000          10.000000   \n",
       "mean          0.258890            0.773875           0.782796   \n",
       "std           0.035569            0.042875           0.031595   \n",
       "min           0.192055            0.701357           0.729632   \n",
       "25%           0.240218            0.740072           0.765759   \n",
       "50%           0.261130            0.784945           0.789165   \n",
       "75%           0.272094            0.804507           0.793287   \n",
       "max           0.318622            0.829669           0.826830   \n",
       "\n",
       "       precision_score__micro  precision_score__macro  \\\n",
       "count               10.000000               10.000000   \n",
       "mean                 0.793424                0.288535   \n",
       "std                  0.042661                0.050794   \n",
       "min                  0.713917                0.206776   \n",
       "25%                  0.770019                0.251891   \n",
       "50%                  0.796566                0.291311   \n",
       "75%                  0.815267                0.307515   \n",
       "max                  0.864236                0.379419   \n",
       "\n",
       "       precision_score__weighted  ...  recall_score__macro  \\\n",
       "count                  10.000000  ...            10.000000   \n",
       "mean                    0.816057  ...             0.257364   \n",
       "std                     0.040900  ...             0.033516   \n",
       "min                     0.737883  ...             0.185742   \n",
       "25%                     0.804088  ...             0.244163   \n",
       "50%                     0.813472  ...             0.259274   \n",
       "75%                     0.844446  ...             0.265805   \n",
       "max                     0.867883  ...             0.312009   \n",
       "\n",
       "       recall_score__weighted  recall_score__samples  jaccard_score__micro  \\\n",
       "count               10.000000              10.000000             10.000000   \n",
       "mean                 0.761034               0.782720              0.634953   \n",
       "std                  0.048066               0.044381              0.045504   \n",
       "min                  0.695205               0.718066              0.558595   \n",
       "25%                  0.713567               0.744621              0.612625   \n",
       "50%                  0.775593               0.796822              0.645179   \n",
       "75%                  0.803753               0.818344              0.655235   \n",
       "max                  0.815877               0.839398              0.694205   \n",
       "\n",
       "       jaccard_score__macro  jaccard_score__weighted  jaccard_score__samples  \\\n",
       "count             10.000000                10.000000               10.000000   \n",
       "mean               0.215581                 0.708030                0.661918   \n",
       "std                0.026899                 0.051132                0.040484   \n",
       "min                0.171804                 0.629265                0.596405   \n",
       "25%                0.199911                 0.664556                0.637618   \n",
       "50%                0.213979                 0.714587                0.670641   \n",
       "75%                0.222074                 0.750225                0.672976   \n",
       "max                0.267533                 0.777955                0.719308   \n",
       "\n",
       "       roc_auc_score  label_ranking_loss  coverage_error  \n",
       "count            0.0           10.000000       10.000000  \n",
       "mean             NaN            0.060978       86.985411  \n",
       "std              NaN            0.017093       12.870083  \n",
       "min              NaN            0.037725       68.509554  \n",
       "25%              NaN            0.050587       76.458898  \n",
       "50%              NaN            0.059758       86.720199  \n",
       "75%              NaN            0.066355       96.865680  \n",
       "max              NaN            0.089780      108.083333  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mass_spectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
